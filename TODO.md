# Optimization Roadmap (SIR → ZASM → lower) — WIP

This TODO focuses on **shrinking + speeding up** the `sircc --emit-zasm → lower` path by:

1) **Input-side optimization** (de-orthogonalize + canonicalize earlier, closer to SIR semantics)
2) **Mid-level optimization** (target-independent rewrites on ZASM IR JSONL)
3) **Output-side optimization** (target-specific lowering: instruction selection, regalloc, peepholes)

Key lesson so far: **LLVM wins because it does global optimization + high-quality codegen.**
Our stack can catch up by combining **semantic rewrites** (we control SIR), **runtime facts** (we control `zem`), and **backend specialization** (we control `lower`).

---

## 0) Success Criteria + Measurement (make it a science experiment)

- [ ] Decide the primary metric(s) we optimize for (pick 2–3):
  - [ ] Unlinked `lower.o` `__TEXT,__text` bytes (primary codegen quality)
  - [ ] Linked exe bytes (secondary; includes runner/lib overhead)
  - [ ] `zem` dynamic step count (or instruction count) for hot programs
  - [ ] `lower --profile` timings per phase
- [ ] Standardize the reporting format (JSONL “build report” records):
  - [ ] `k:opt_report` with fields `{tool, input_hash, output_hash, sizes, deltas, timings, git_rev}`
  - [ ] Store reports under `build/opt_reports/` (or `dist/test/reports/` later)
- [ ] Establish a small “benchmark corpus” (loop-heavy, mem-heavy, branchy, call-heavy):
  - [ ] `sendloop_uniform` (forces all paths)
  - [ ] `sendloop_mono` (has cold paths; good for pruning)
  - [ ] memcopy/fill microcases (len=1/2/4/8, align variants)
  - [ ] call-heavy “syscall” loops (zi_* calls with small buffers)
  - [ ] 1–2 “nasty HL artifacts” (Smalltalk-ish patterns) once the sugaring model stabilizes

---

## 1) Ownership + Contracts (Zem vs Lower vs “Front”)

- [ ] Write a short “ownership + contracts” doc (tool boundaries):
  - [ ] Target-independent transforms live in **`zem`** (or “zemopt” pipeline)
  - [ ] Target-specific codegen + regalloc/peepholes live in each **`lower`**
  - [ ] `sircc` is responsible for correctness + producing a reasonable canonical ZASM IR shape
- [ ] Define the interchange contract(s) between stages:
  - [ ] **Optimized IR JSONL** contract: `zasm-v1.1` records + invariants
  - [ ] **Hint/profile JSONL** contract(s): “facts” streams consumed by `lower` (out-of-band sidecar JSONL)
  - [ ] Versioning rules (backward compatibility expectations; strict vs best-effort)
- [ ] Capture schema constraints explicitly (so we don’t fight the format):
  - [ ] ZASM v1.1 record schema is **strict** (`additionalProperties:false` on record variants)
  - [ ] Therefore: optimization hints should be either:
    - [ ] **sidecar hint JSONL** (preferred; schema-free, versioned independently), or
    - [ ] encoded using existing, schema-legal fields (`id`, `loc.unit`, `src_ref`), with clear rules
- [ ] Fix stable “site identity” for hints/profiles:
  - [ ] Prefer stable `site_id` over `pc` (pc breaks when IR is rewritten)
  - [ ] Options for stable IDs:
    - [ ] ZASM record `id` (if always emitted + preserved through transforms)
    - [ ] explicit `site_id` directive records (generated by `sircc` or `zemopt`)
    - [ ] structural hashing of a window (shape-hash) + disambiguator
- [ ] Decide what must be verified by hash vs best-effort:
  - [ ] `module_hash` required for strict profiles
  - [ ] `--allow-mismatch` semantics (when safe, when dangerous)

---

## 2) Front De-orthogonaliser (Input-side: SIR → better ZASM shapes)

Goal: reduce “semantic leveling orthogonality tax” by picking better shapes *before* we hit ZASM.

- [ ] Introduce “canonical intent” propagation from the upstream intrinsic AST (GL)
  - [ ] Treat the intrinsic vocabulary (`Unit/Proc/Block/While/If/For/DoWhile/Bin/Unary/Call/...`) as the **language-independent source of truth**
  - [ ] Require stable `gl_id` for every intrinsic node (per compilation unit)
  - [ ] Carry `{gl_id, gl_kind}` through SIR as **debug metadata only** (never required for correctness)
  - [ ] At SIR → ZASM lowering, emit sidecar hints keyed by ZASM record ids (`zid`) and/or spans (id ranges)
  - [ ] Keep “intent” additive and conservative: hints guide optimization but must never change semantics

- [ ] Identify high-ROI de-orthogonalizations (semantic-preserving, goal-directed):
  - [ ] `mem.fill/copy` specialization:
    - [ ] If `len` is constant and in `{1,2,4,8}`, emit specialized straight-line ops (or marked sites)
    - [ ] If `len` is small but not constant, emit a small dispatch ladder (bounded) instead of full loop
  - [ ] Conditionals:
    - [ ] Fold `cmp(x, const)` patterns into tighter branch forms where possible
    - [ ] Prefer “branch on compare” patterns that avoid producing a boolean value node
  - [ ] CFG value flow:
    - [ ] Minimize bparam slot traffic: keep frequently-used values in registers across edges when legal
    - [ ] Reduce pointless block params (when args are identical along all preds)
  - [ ] Addressing:
    - [ ] Detect base+const-offset patterns early (avoid multi-step ptr arithmetic)
    - [ ] Canonicalize ptr math so `lower` can fold addressing modes
  - [ ] Call ABI shaping:
    - [ ] Canonicalize argument materialization order to maximize reuse of already-loaded values
- [ ] Add a “shape annotation” mechanism in ZASM IR:
  - [ ] Preferred: emit a **sidecar hint stream** (JSONL) keyed by stable site identity
    - [ ] `sircc --emit-zasm` also writes `<out>.hints.jsonl` (or `--emit-hints PATH`)
    - [ ] Each hint references either:
      - [ ] `site_id` (front-end stable), plus a mapping to ZASM record `id`s, or
      - [ ] directly the ZASM record `id` (when hint is record-local)
    - [ ] `zemopt` preserves record `id` on rewrites where possible and can emit an updated mapping when it re-forms code
    - [ ] Initial hint schema (sidecar, v1):
      - [ ] `hint_meta`: `{k:"hint_meta", ver:1, module_hash, producer, unit}`
      - [ ] `hint`: `{k:"hint", ver:1, zid, span?, gl_id?, gl_kind?, intent, props:{...}}`
      - [ ] `map` (optional): `{k:"map", ver:1, gl_id, zspan:[zid_lo,zid_hi]}` when a single `hint` cannot express 1→many mapping
    - [ ] Initial `intent` vocabulary (keep tiny; extend only with tests):
      - [ ] `loop` (`props:{kind:"while|for|dowhile", header_lbl?, latch_lbl?, iv?}`)
      - [ ] `counted_loop` (`props:{iv, step, bound_kind:"const|var", direction}`)
      - [ ] `bulk_memcpy` / `bulk_memset` (`props:{len_kind, len?, align?, volatile?}`)
      - [ ] `bounds_check` (`props:{trap_code?, unsigned?, index_width?}`)
      - [ ] `dyn_dispatch` (`props:{mono:boolean, cache:"inline|pic|none", miss_path:boolean}`)
      - [ ] `cold_path` / `error_path` (`props:{reason?}`)
      - [ ] `call_abi_bridge` (`props:{abi:"c|zabi", callee_kind:"extern|intrinsic|local"}`)
  - [ ] Fallback (schema-legal, in-band): use `loc.unit` as a tiny tag channel
    - [ ] Example: `loc.unit:"sircc.site=123 origin=sir.mem.copy policy=inline_small"`
    - [ ] Keep this conservative: short, parseable, and never required for correctness
  - [ ] Examples:
    - [ ] `bulk_mem_policy: inline_small` with thresholds
    - [ ] `prefer_cbz` when compare-to-zero is present
    - [ ] `keep_in_reg: <name>` for loop-invariants (conservative)

---

## 3) ZASM Target-Independent Optimizer (Mid-end on JSONL)

Implement as `zem --opt-out PATH` (or a sibling tool with the same rules):

- [ ] Parse ZASM JSONL into:
  - [ ] basic blocks (labels), terminators (JR/JR cond/RET/CALL?), fallthrough edges
  - [ ] def/use for registers + known slots + symbols (conservative)
- [ ] CFG simplification (big ROI, especially for monomorphic/biased code):
  - [ ] Reachability: delete unreachable blocks
  - [ ] Jump threading: `JR L1` to block that immediately `JR L2` → `JR L2`
  - [ ] Block merge: merge trivial blocks with single pred/succ and no label users
  - [ ] Remove redundant labels (unreferenced)
- [ ] Block-local peepholes (safe, huge volume):
  - [ ] Kill redundant moves: `LD r, r`, `LD DE, DE`, `LD HL, HL`
  - [ ] Remove “DROP r immediately overwritten”
  - [ ] Simplify compare/branch idioms:
    - [ ] `CP r, 0` + `JR NE` → prefer `JR` patterns if ISA supports equivalent
  - [ ] Constant folding for arithmetic with immediates
  - [ ] Copy propagation within a block
- [ ] Dead computation elimination (start block-local, conservative):
  - [ ] Remove computations whose results are never used and have no side effects
  - [ ] Define side-effect rules for CALL / memory ops / volatile forms
- [ ] Dead store elimination (conservative alias rules):
  - [ ] Slot stores never read → remove
  - [ ] Store→store same slot without intervening read → remove earlier store
- [ ] Validation (“do-no-harm”):
  - [ ] `zem --opt-validate`: run original vs optimized and compare stdout/stderr/rc
  - [ ] Add negative tests: optimizer must not delete necessary side effects

Stretch/advanced (still doable):
- [ ] E-graph rewrite engine for peepholes + algebraic laws (bounded)
- [ ] Superoptimizer for tiny straight-line blocks (time-capped)

---

## 4) Zem: Profiling + Facts Emission (beyond `--pgo-len-out`)

- [ ] Extend profiles:
  - [ ] Hotness: block counts + edge counts
  - [ ] Site histograms: lengths, immediate values, branch bias
- [ ] Emit “facts” usable by any backend:
  - [ ] slot not address-taken (if observable)
  - [ ] constant-at-site (when runtime proves it)
  - [ ] call target set (monomorphic call sites)
- [ ] Cross-link profiles to intrinsic intent (superpower):
  - [ ] Allow `zem` to ingest `<out>.hints.jsonl` and join it with runtime profiles
  - [ ] Emit “intent-weighted” facts (e.g. hot `bulk_memcpy` sites with stable ids + observed len histos)
  - [ ] Use intent to avoid bad generalizations (e.g. don’t specialize cold error paths)
- [ ] Document hint/profile schema(s) (`k:` record types), version them
- [ ] Robust-ingest tests:
  - [ ] fuzz parser for hint JSONL shapes
  - [ ] backward-compat tests for older hint versions

---

## 5) Lower (arm64): Backend Quality + Hint Consumption

Goal: make `lower.o __text` converge toward LLVM `--emit-obj` sizes.

- [ ] Observability:
  - [ ] `--debug-pgo-len`: report loaded sites, bulk ops seen, specialized count, rejections + reasons
  - [ ] `--debug-regalloc`: spills, live ranges (summary)
  - [ ] `--emit-map/--emit-pc-map`: keep stable debugging while rewriting
- [ ] Bulk-mem lowering policy (PGO-guided):
  - [ ] Special-case `FILL/LDIR` for hot tiny lengths (1/2/4/8)
  - [ ] Keep generic path but only when profitable (cost model; don’t just add code)
  - [ ] Allow “no specialization” if profile says length is uniform but large
- [ ] Peepholes (high ROI):
  - [ ] remove redundant address calc chains
  - [ ] AArch64 addressing-mode folding (imm12 scaled, register offset)
  - [ ] compare/branch canonicalization (`cbz/cbnz` where legal)
- [ ] Regalloc strategy (incremental):
  - [ ] Block-local reg allocation for temps (small pool)
  - [ ] Spill around calls; reuse regs across sequences
  - [ ] Optional: loop-invariant hoisting guided by hotness
- [ ] Layout:
  - [ ] hot/cold block ordering using hotness hints
  - [ ] align hot loops reasonably; keep cold out-of-line

---

## 6) Tests + Guardrails (close the LLVM gap safely)

- [ ] Differential correctness:
  - [ ] `zem` original vs `zemopt` optimized must match stdout/stderr/rc
  - [ ] `lower` output vs LLVM output must match stdout/rc for fixtures
- [ ] Size tracking:
  - [ ] Track `lower.o __text` and LLVM `--emit-obj __text` per fixture
  - [ ] Add tolerant thresholds (no regression) per target
- [ ] Coverage-based debloat:
  - [x] Pipeline exists: `zem --coverage-out` + `zem --strip uncovered-delete` → `lower` (in tests)
  - [ ] Add “assurance mode”: require stable coverage across N runs (`zem --shake`) before stripping

---

## 7) Reality Check: Why “hello world” is still big

- [ ] Keep separating:
  - [ ] payload `lower.o __text` (what we control in lowering)
  - [ ] linked exe size (runner + lib + Mach-O overhead)
- [ ] Add optional “payload-only” size report (object file only) everywhere in the harness
